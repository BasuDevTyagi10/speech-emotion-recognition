{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing required packages\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import os\n",
    "import sys\n",
    "import random\n",
    "\n",
    "import plotly.express as px\n",
    "import matplotlib.pyplot as plt\n",
    "from IPython.display import Audio\n",
    "\n",
    "import librosa\n",
    "import librosa.display\n",
    "\n",
    "import warnings\n",
    "if not sys.warnoptions:\n",
    "    warnings.simplefilter(\"ignore\")\n",
    "warnings.filterwarnings(\"ignore\", category=DeprecationWarning) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = pd.read_csv(\"./data/dataset.csv\")\n",
    "dataset.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First let's plot the count of each emotions in our dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "count_df = dataset.groupby('Emotions').count().reset_index().rename(columns={'Path': 'Count'})\n",
    "\n",
    "fig = px.bar(count_df, x='Emotions', y='Count', color='Emotions', title=\"Count of each emotion\")\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Inference:\n",
    "- The plot shows 8 different emotions from our dataset.\n",
    "- The dataset is well distributed except for _calm_ and _surprise_ emotions."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also plot waveplots and spectograms for audio signals\n",
    "\n",
    "* **Waveplots** - Waveplots let us know the loudness of the audio at a given time.\n",
    "* **Spectograms** - A spectrogram is a visual representation of the spectrum of frequencies of sound or other signals as they vary with time. Itâ€™s a representation of frequencies changing with respect to time for given audio/music signals."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_waveplot(data, sr, e):\n",
    "    plt.figure(figsize=(10, 3))\n",
    "    plt.title('Waveplot for audio with {} emotion'.format(e), size=15)\n",
    "    librosa.display.waveshow(data, sr=sr)\n",
    "    plt.show()\n",
    "\n",
    "def create_spectrogram(data, sr, e):\n",
    "    # stft function converts the data into short term fourier transform\n",
    "    X = librosa.stft(data)\n",
    "    Xdb = librosa.amplitude_to_db(abs(X))\n",
    "    plt.figure(figsize=(12, 3))\n",
    "    plt.title('Spectrogram for audio with {} emotion'.format(e), size=15)\n",
    "    librosa.display.specshow(Xdb, sr=sr, x_axis='time', y_axis='hz')   \n",
    "    plt.colorbar()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_plots(emotion):\n",
    "    # get random value from dataset\n",
    "    try:\n",
    "        path = np.random.choice(np.array(dataset.Path[dataset.Emotions==emotion]))\n",
    "    except ValueError as error:\n",
    "        print(\"Error retriving values for:\", emotion)\n",
    "        print(\"Error message:\", error)\n",
    "        return\n",
    "    print(\"File at path:\",path)\n",
    "    data, sampling_rate = librosa.load(path)\n",
    "    create_waveplot(data, sampling_rate, emotion)\n",
    "    create_spectrogram(data, sampling_rate, emotion)\n",
    "    display(Audio(path))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's plot the waveplot and spectrogram for each emotion in the dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Angry"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "create_plots(\"angry\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. Calm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "create_plots(\"calm\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. Disgust"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "create_plots(\"disgust\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4. Fear"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "create_plots(\"fear\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "5. Happy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "create_plots(\"happy\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "6. Neutral"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "create_plots(\"neutral\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "7. Sad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "create_plots(\"sad\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "8. Surprise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "create_plots(\"surprise\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Data Augmentation\n",
    "\n",
    "In this process we create new synthetic data samples by adding small perturbations on our initial training set. The objective is to make our model invariant to those perturbations and enhace its ability to generalize. In order to this to work adding the perturbations must conserve the same label as the original training sample.\n",
    "\n",
    "For the scope of this analysis we will add the following changes to our audio files:\n",
    "- Noise\n",
    "- Stretch\n",
    "- Shift\n",
    "- Pitch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def noise(data):\n",
    "    noise_amp = 0.035*np.random.uniform()*np.amax(data)\n",
    "    data = data + noise_amp*np.random.normal(size=data.shape[0])\n",
    "    return data\n",
    "\n",
    "def stretch(data, rate=0.8):\n",
    "    return librosa.effects.time_stretch(data, rate)\n",
    "\n",
    "def shift(data):\n",
    "    shift_range = int(np.random.uniform(low=-5, high = 5)*1000)\n",
    "    return np.roll(data, shift_range)\n",
    "\n",
    "def pitch(data, sampling_rate, pitch_factor=0.7):\n",
    "    return librosa.effects.pitch_shift(data, sampling_rate, pitch_factor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# taking any example and checking for techniques.\n",
    "example_row = dataset.sample()\n",
    "path = example_row.Path.values[0]\n",
    "emotion = example_row.Emotions.values[0]\n",
    "data, sample_rate = librosa.load(path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Original Audio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "create_waveplot(data, sample_rate, emotion)\n",
    "Audio(path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. Audio with Noise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "audio_with_noise = noise(data)\n",
    "create_waveplot(audio_with_noise, sample_rate, emotion)\n",
    "Audio(audio_with_noise, rate=sample_rate)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. Audio with Stretch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "audio_with_stretch = stretch(data)\n",
    "create_waveplot(audio_with_stretch, sample_rate, emotion)\n",
    "Audio(audio_with_stretch, rate=sample_rate)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4. Audio with Shift"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "audio_with_shift = shift(data)\n",
    "create_waveplot(audio_with_shift, sample_rate, emotion)\n",
    "Audio(audio_with_shift, rate=sample_rate)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "5. Audio with Noise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "audio_with_pitch = pitch(data, sample_rate)\n",
    "create_waveplot(audio_with_pitch, sample_rate, emotion)\n",
    "Audio(audio_with_pitch, rate=sample_rate)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Conclusion:\n",
    "1. The dataset is well distributed for all the labels/classes (except for _calm_ and _surprise_ emotions).\n",
    "2. The length for all audio files varies between 2.5 to 3 seconds where the first few milliseconds provide no help in classifying it.\n",
    "3. Adding perturbations to our audio data will enhance the model's ability to generalize and thus adding noise, stretch, shift and pitch will help us achieve this goal."
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "c49f76732089423fa66cd4eaaaafdc2d350d8afbaeade1d29e61cdb22b6de2f3"
  },
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "venv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
